{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Sample Text\n",
    "text = \"\"\"The AI, called Pluribus, defeated poker professional Darren Elias, who holds the \n",
    "record for most World Poker Tour titles, and Chris \"Jesus\" Ferguson, winner of six World Series of Poker events. \n",
    "Each pro separately played 5,000 hands of poker against five copies of Pluribus. In another experiment involving \n",
    "13 pros, all of whom have won more than $1 million playing poker, Pluribus played five pros at a time for a total \n",
    "of 10,000 hands and again emerged victorious.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Sentences:  ['The AI, called Pluribus, defeated poker professional Darren Elias, who holds the \\nrecord for most World Poker Tour titles, and Chris \"Jesus\" Ferguson, winner of six World Series of Poker events.', 'Each pro separately played 5,000 hands of poker against five copies of Pluribus.', 'In another experiment involving \\n13 pros, all of whom have won more than $1 million playing poker, Pluribus played five pros at a time for a total \\nof 10,000 hands and again emerged victorious.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize paragraph into individual sentences\n",
    "nltk_sentences = sent_tokenize(text)\n",
    "print(\"Tokenized Sentences: \", nltk_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tokenized Words:  ['The', 'AI', ',', 'called', 'Pluribus', ',', 'defeated', 'poker', 'professional', 'Darren', 'Elias', ',', 'who', 'holds', 'the', 'record', 'for', 'most', 'World', 'Poker', 'Tour', 'titles', ',', 'and', 'Chris', '``', 'Jesus', \"''\", 'Ferguson', ',', 'winner', 'of', 'six', 'World', 'Series', 'of', 'Poker', 'events', '.', 'Each', 'pro', 'separately', 'played', '5,000', 'hands', 'of', 'poker', 'against', 'five', 'copies', 'of', 'Pluribus', '.', 'In', 'another', 'experiment', 'involving', '13', 'pros', ',', 'all', 'of', 'whom', 'have', 'won', 'more', 'than', '$', '1', 'million', 'playing', 'poker', ',', 'Pluribus', 'played', 'five', 'pros', 'at', 'a', 'time', 'for', 'a', 'total', 'of', '10,000', 'hands', 'and', 'again', 'emerged', 'victorious', '.']\n"
     ]
    }
   ],
   "source": [
    "#Tokenize paragraph/sentence into individual words\n",
    "nltk_words = word_tokenize(text)\n",
    "print(\"Tokenized Words: \", nltk_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Original Text containing punctuation\n",
    "text_with_punctuation = \"John's burger was so! delicious that I ate it fully, #Whataburger.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text Without Punctuation: ['John', 's', 'burger', 'was', 'so', 'delicious', 'that', 'I', 'ate', 'it', 'fully', 'Whataburger']\n"
     ]
    }
   ],
   "source": [
    "#Reoving punctuation\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "\n",
    "tokenize_text = RegexpTokenizer(r'\\w+') #Here \\w+ is used for matching one or more word characters\n",
    "Output = tokenize_text.tokenize(text_with_punctuation)\n",
    "print(\"Text Without Punctuation:\", Output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "text_st_words = \"An apple a day keeps a doctor away, who was the person quoted this saying?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Invoke all the english stopwords\n",
    "stop_word_list = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Tokenize sentence into words\n",
    "text = word_tokenize(text_st_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Create an empty list and append non stop words in it\n",
    "\n",
    "new_word_list = []\n",
    "for w in text:\n",
    "    if w not in stop_word_list: new_word_list.append(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Text: ['An', 'apple', 'a', 'day', 'keeps', 'a', 'doctor', 'away', ',', 'who', 'was', 'the', 'person', 'quoted', 'this', 'saying', '?']\n"
     ]
    }
   ],
   "source": [
    "print(\"Original Text:\", text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text after Stop Words are removed: ['An', 'apple', 'day', 'keeps', 'doctor', 'away', ',', 'person', 'quoted', 'saying', '?']\n"
     ]
    }
   ],
   "source": [
    "#Stop words like a, an, the are removed\n",
    "print(\"Text after Stop Words are removed:\", new_word_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
